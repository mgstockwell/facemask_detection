{"cells":[{"cell_type":"markdown","metadata":{"id":"oVB6E_LHP67I"},"source":["# Deploy ML Model\n","https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html\n","https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#deploy-tensorflow-serving-models\n","https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/\n","\n","\n","After a TensorFlow estimator has been fit, it saves a TensorFlow SavedModel in the S3 location defined by output_path. You can call deploy on a TensorFlow estimator to create a SageMaker Endpoint, or you can call transformer to create a Transformer that you can use to run a batch transform job."]},{"cell_type":"markdown","source":["## AWS Setup\n","\n","You will need to upload two files with no extension, \"credentials\" and \"config\".\n","\n","The credentials file has your API key, config is preferred region\n","\n","Put the following in each, change values to yours:\n","<hr>\n","credentials\n","\n","```\n","[default]\n","aws_access_key_id = AKIAXN6R7JXYxxxxxxxx \n","aws_secret_access_key = 1prI4W8J254zR5/ishEilmqskaZLOnazxxxxxxxx\n","```\n","<hr>\n","config\n","\n","```\n","[default]\n","region = us-east-1\n","```"],"metadata":{"id":"SoN5A257G2VI"}},{"cell_type":"code","source":["!apt-get update -q >apt-get_install.og\n","!pip3 -q install awscli\n","!pip3 -q install boto3\n","!pip3 -q install sagemaker\n","!pip3 -q install opendatasets\n","!pip freeze >requirements.txt\n","import boto3\n","from google.colab import files\n","import os, sys, stat\n","import shutil\n","\n","# Set the bucket name that will be used everywhere\n","aws_bucket = '511004593648-msds436'\n","\n","# check if AWS credentials already loaded, if not prompt for upload\n","aws_folder = os.path.expanduser('~/.aws')\n","path_to_file = f'{aws_folder}/credentials'\n","print(\"AWS credentials location:\", path_to_file)\n","\n","if os.path.exists(path_to_file):\n","  print(\"AWS credentials found in ~/.aws/credentials\")\n","else:\n","  print('-'*80)\n","  print(\"Upload your AWS credentials and config files:\")\n","  files_uploaded = files.upload()\n","  os.makedirs(aws_folder, exist_ok=True)\n","  shutil.copy('credentials',f'{aws_folder}/credentials')\n","  shutil.copy('credentials',f'{aws_folder}/config')\n","  os.chmod(f'{aws_folder}/credentials', stat.S_IRWXU)\n","  os.chmod(f'{aws_folder}/config', stat.S_IRWXU)\n","  print(\"files uploaded: \",files_uploaded.keys)\n","\n","# all ok? this command should work\n","comprehend = boto3.client(service_name='comprehend', region_name=\"us-east-1\")\n","text = \"Machine learning will automate jobs that most people thought could only be done by people.\" #~Dave Waters\n","print(\"text to perform sentiment analysis: \\n\",text)\n","comprehend.detect_sentiment(Text=text, LanguageCode='en')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ppZu2yPG6VY","executionInfo":{"status":"ok","timestamp":1647055144987,"user_tz":300,"elapsed":26615,"user":{"displayName":"Mark Stockwell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5aqK868qUNEkW7VCMmPwVj2LKc3lmBHoRchohrA=s64","userId":"11398695282082732279"}},"outputId":"ed425be2-a6fb-48a2-aa88-d6222eaf9053"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sagemaker 2.78.0 requires boto3>=1.20.21, but you have boto3 1.18.0 which is incompatible.\n","awscli 1.22.73 requires botocore==1.24.18, but you have botocore 1.21.65 which is incompatible.\u001b[0m\n","AWS credentials location: /root/.aws/credentials\n","AWS credentials found in ~/.aws/credentials\n","text to perform sentiment analysis: \n"," Machine learning will automate jobs that most people thought could only be done by people.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'ResponseMetadata': {'HTTPHeaders': {'content-length': '162',\n","   'content-type': 'application/x-amz-json-1.1',\n","   'date': 'Sat, 12 Mar 2022 03:19:05 GMT',\n","   'x-amzn-requestid': '7b9db77b-2d59-4046-8a37-8429bc084dc4'},\n","  'HTTPStatusCode': 200,\n","  'RequestId': '7b9db77b-2d59-4046-8a37-8429bc084dc4',\n","  'RetryAttempts': 0},\n"," 'Sentiment': 'NEUTRAL',\n"," 'SentimentScore': {'Mixed': 0.009578169323503971,\n","  'Negative': 0.01551244780421257,\n","  'Neutral': 0.8685871362686157,\n","  'Positive': 0.10632215440273285}}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Step 1: Setup"],"metadata":{"id":"-YMP0odEF9zh"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"JG4qQgg8PyBI","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1647055731836,"user_tz":300,"elapsed":222,"user":{"displayName":"Mark Stockwell","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5aqK868qUNEkW7VCMmPwVj2LKc3lmBHoRchohrA=s64","userId":"11398695282082732279"}},"outputId":"d8f11546-5305-443c-b1a3-f99b23c4b87a"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-56e289a068e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mboto3_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_execution_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboto3_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mget_execution_role\u001b[0;34m(sagemaker_session)\u001b[0m\n\u001b[1;32m   4424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4425\u001b[0m         \u001b[0msagemaker_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4426\u001b[0;31m     \u001b[0marn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_caller_identity_arn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\":role/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'get_caller_identity_arn'"]}],"source":["\n","import boto3\n","import sagemaker\n","\n","boto3_sess = boto3.Session()\n","role = sagemaker.get_execution_role(boto3_sess)\n","sess = sagemaker.Session()\n","bucket = sess.default_bucket()\n","\n","\n","import tensorflow as tf\n","print(tf.__version__)  # This notebook runs on TensorFlow 1.15.x or earlier\n","tf_framework_version = tf.__version__\n","\n","# reference: https://github.com/keras-team/keras/issues/14265\n","!pip install \"h5py==2.10.0\"\n","import h5py\n","import numpy as np"]},{"cell_type":"markdown","source":["## Step 4. Convert TensorFlow model to an Amazon SageMaker-readable format\n","We skipped steps since using a *.pb protocol buffer format"],"metadata":{"id":"wijuybP0GLn2"}},{"cell_type":"code","source":[""],"metadata":{"id":"4kzbsJa-GVu0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Op_OyEHBXMGN"},"source":["## Batch Transformation\n","\n","From https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#run-a-batch-transform-job \n","\n","and https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform\n","\n","Create transformer object and run over an in input directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"209XzgXDXRkh"},"outputs":[],"source":["bucket = myBucket # The name of the S3 bucket where the results are stored\n","prefix = 'batch-results' # The folder in the S3 bucket where the results are stored\n","\n","batch_output = 's3://{}/{}/results'.format(bucket, prefix) # The location to store the results\n","\n","tf_transformer = tf_estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n","\n","tf_transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DeploySagemakerModel.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}